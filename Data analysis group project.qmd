---
title: "Report on Body mass index(BMI)"
authors: "William Lang,  Freya Lynn, Abbey O'Donnell, Soultan Albarghouth"
       
execute: 
  echo: false
  eval: true
number-sections: true
format:
  html:
    embed-resources: true
editor_options: 
  chunk_output_type: console
---

```{r}
#| echo: false
#| warning: false
#| message: false
library(ggplot2)
library(dplyr)
library(tidyr)
library(tidymodels)
library(sjPlot)
library(performance)
library(kableExtra)
library(gt)
library(tidyverse)
library(moderndive)
library(skimr)
library(gapminder)
```

# Introduction {#sec-intro}

Body mass index(BMI) is an important variable in determing how healthy an indivdual is and is affected by such variables as diet and exercise. The following report will through stastical analysis answer the questions of intrest:

1.  Has the body mass index (BMI) in Scotland changed over the given years of the Scottish Health Survey?

2.  Are there any differences in the BMI distribution by age, gender, socio-economic status or lifestyle factors?

# Exploratory Analysis {#sec-EA}

```{r}
#| echo: false
#| label: tbl-summmary
#| tbl-cap:  Mean, median and standard deviation (sd) of BMI by year.

library(gt)
library(dplyr)
bmi.data <- read.csv("DAProject6.csv")
bmi.data.year <- bmi.data |>
  select(BMI, Year)


```

| Year | Mean  | Median | Standard deviation |
|------|-------|--------|--------------------|
| 2016 | 28.03 | 27.28  | 5.79               |
| 2015 | 28.02 | 27.26  | 5.53               |
| 2014 | 27.84 | 27.17  | 5.21               |
| 2013 | 27.81 | 27.08  | 5.28               |

: Mean,Median and standard deviation of BMI by year

Therefore we can clearly see that the mean and median BMI has slightly increased over the years from 2013-2016. We can also see that the variation has also slightly increased from 2014-2016.

```{r}
#| label: box-bmi-year
#| fig-cap: Boxplot of BMI by Year
#| fig-width: 4
#| fig-height: 3
  
bmi.year <- bmi.data.year
bmi.year$Year <- as.factor(bmi.year$Year)


ggplot(bmi.year, aes(y = BMI, x = Year, fill = Year))+
  geom_boxplot() +
  labs(x = "Year", y = "BMI", title = "BMI over the different years") +
  scale_fill_discrete(guide = "none")
```

We can therefore see from the boxplots that there is a slight increase in BMI over the years and that the normality assumption is not vaild due to the number of outliers in the data.

## Analyzing BMI Distribution by Different Factors

### Age

```{r}
#| label: fig-line
#| fig.cap: "The linear relation ship between Age and BMI"
#| warning: FALSE
#| message: FALSE
#| fig-width: 4
#| fig-height: 3

ggplot(bmi.data, aes(x = Age, y = BMI)) + 
  geom_point(alpha = 0.5) +
  geom_smooth(method = "lm",se=FALSE, col = "blue") +
  theme_minimal() + labs(title = "BMI vs Age", x = "Age", y = "BMI")
```

From @fig-line we can see that there is a weak linear relation between age and BMI.

This weak relation tells that there is a small negative effect of the Age on the BMI.

### Gender

```{r}
#| label: fig-sex
#| fig.cap: "The boxplot of the Sex VS BMI"
#| warning: FALSE
#| message: FALSE 
#| fig-width: 4
#| fig-height: 3
ggplot(bmi.data, aes(x = Sex, y = BMI, fill = Sex)) + 
  geom_boxplot() + 
  theme_minimal() + 
  labs(title = "BMI Distribution by Gender", x = "Gender", y = "BMI")
```

From @fig-sex we can see that greater variability in BMI among females compared to males,however having the same median indicates that while central tendency is similar, BMI distribution differs between genders.

### Education

```{r}
#| warning: FALSE
#| message: FALSE
#| label: fig-education
#| fig.cap: "BMI Distribution by Education"
#| fig-width: 6
#| fig-height: 4

ggplot(bmi.data, aes(x = Education, y = BMI, fill = Education)) +
  geom_boxplot() +
  theme_minimal() + 
  labs(title = "BMI Distribution by Education", x = "Education Level",
  y = "BMI")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1))
```

From @fig-education we can see that the small different in medians suggest a minor impact of education on BMI. However the variation on boxplots spreads,indicates that higher education levels might be associated with lower BMI variability.

### Veg

```{r}
#| warning: FALSE
#| message: FALSE
#| label: fig-veg
#| fig-width: 6
#| fig-height: 3

plot1<-ggplot(bmi.data, aes(x = Veg, y = BMI, fill = Veg)) + 
  geom_boxplot() + 
  theme_minimal() + 
  labs(title = "BMI vs Vegetable Consumption", x = "Vegetable Intake", y = "BMI")

plot2<-ggplot(bmi.data, aes(x = Fruit, y = BMI, fill = Fruit)) +
  geom_boxplot() + 
  theme_minimal() + 
  labs(title = "BMI vs Fruit Consumption", x = "Fruit Intake", y = "BMI") 

library(patchwork)
plot1|plot2
```

From @fig-veg since both fruit and vegetarian have same boxplots distribution and median,it suggest that neither of them significantly effect BMI distribution.This indicates that BMI is similar regardless of whether a person having a fruit or vegetable.

# Formal Analysis {#sec-FA}

## Question 1

To determine whether BMI has changed in Scotland over the given years, we fit a regression model, where BMI is our outcome variable y and Year is our categorical variable x :

```{r}
data <- read.csv("DAProject6.csv")

data$Year <- as.factor(data$Year)
  
model1 <- linear_reg() |>
  fit(BMI ~ Year, data = data)
```

We can use the estimates obtained here to fit our regression equation as follows:

$$
BMI = \alpha + \beta_{2014}\cdot I_{2014}(x) +\beta_{2015}\cdot I_{2015}(x)+\beta_{2016}\cdot I_{2016}(x)
$$

where

-   the intercept $\alpha$ is the mean BMI for our baseline year, 2013;

-   $\beta_{year}$ is the difference in the mean BMI in a given year relative to the baseline year 2013; and

-   $I_{year}(x)$ is an indicator function such that

    $$
    I_{year}(x) = \left\{ \begin{array}{rcl}\
    1 & \mbox{if x matches the given year}
     \\ 0 & \mbox{otherwise} 
    \end{array}\right.
    $$

We can now assess the fit of our model.

```{r}

regression_points <- get_regression_points(model1$fit)

```

We first do this by obtaining residuals. These are then plotted by year to test our assumptions:

```{r}
#| label: fig-reg-scatter
#| fig-cap: Scatterplot of Residuals by Year
#| fig-width: 4
#| fig-height: 3

ggplot(regression_points, aes(x = Year, y = residual)) +
  geom_jitter(width = 0.1) + 
  labs(x = "Year", y = "Residual") +
  geom_hline(yintercept = 0, col = "blue")

```

@fig-reg-scatter shows that the residuals are evenly spread and have mean zero. Therefore our assumption of constant variance appears to be valid.

We next plot a histogram to check that the residuals are normally distributed:

```{r}
#| label: fig-reg-hist 
#| fig-cap: Histogram of Residuals
#| fig-width: 4
#| fig-height: 3
ggplot(regression_points, aes(x = residual)) +
  geom_histogram(binwidth = 5, color = "white") +
  labs(x = "Residual")
```

@fig-reg-hist shows that the residuals are centered at zero and are bell shaped. Therefore our assumption of normality appears to be valid.

## Question 2

```{r}
bmi <- read_csv("DAProject6.csv")
lm_spec <- linear_reg() |> set_engine("lm")
bmi.model1 <- lm_spec |> fit(BMI ~ Age + Sex + Education + Veg + Fruit +Year, data = bmi)
bmi.model1 <- bmi.model1 |> extract_fit_engine()
get_regression_table(bmi.model1)
```

```{r}

lm_spec <- linear_reg() 
bmi.model1.int <- lm_spec |> fit(BMI ~ Age * Sex * Education * Veg * Fruit * Year, data = bmi)
bmi.model1.int <- bmi.model1.int |> extract_fit_engine()
get_regression_table(bmi.model1.int)
```

```{r}


library(tidymodels)
library(moderndive) 
library(broom)      
library(dplyr)

lm_spec <- linear_reg()

bmi_full_model <- lm_spec %>% 
  fit(BMI ~ Age + Sex + Education + Veg + Fruit + Year, data = bmi)


bmi_full_model_fit <- bmi_full_model |> extract_fit_engine()
full_results <- tidy(bmi_full_model_fit, conf.int = TRUE)
print(full_results)


bmi_model_int <- lm_spec |>
  fit(BMI ~ Age + Sex + Education + Veg + Fruit + Year + 
        Age:Sex +           
        Sex:Education +     
        Veg:Fruit +         
        Year:Age,           
      data = bmi)


bmi_model_int_fit <- bmi_model_int |> extract_fit_engine()

int_results <- get_regression_table(bmi_model_int_fit)
print(int_results)


model_comparison <- bind_rows(
  tibble(model = "Full Model", 
         AIC = AIC(bmi_full_model_fit),
         BIC = BIC(bmi_full_model_fit)),
  tibble(model = "Interaction Model", 
         AIC = AIC(bmi_model_int_fit),
         BIC = BIC(bmi_model_int_fit))
)
print(model_comparison)


plot(bmi_model_int_fit)
```

## Question 2

To investigate changes in BMI across age, gender, fruit and veg consumption or socioeconomic status, we will use multiple linear regression. Before we do this we will check that the BMI data is normally distributed.

```{r}

library(ggplot2)
library(dplyr)
library(skimr)
library(tidymodels)
library(moderndive) 
library(broom)      
library(dplyr)
library(tidyverse)
library(corrplot)
library(knitr)
bmi.data <- read_csv("DAProject6.csv", show_col_types = FALSE)
plot1<-ggplot(bmi.data, aes(x = BMI)) +
  geom_histogram(binwidth = 1, fill = "blue4", color = "black", alpha = 0.5) +
  geom_density(color = "red", linewidth = 1) +
  labs(title = "Distribution of BMI",
       x = "BMI",
       y = "Frequency") 
plot2 <- ggplot(bmi.data, aes(sample = BMI)) +
  geom_qq() +
  geom_qq_line() +
  labs(title = "QQ Plot of BMI")

library(patchwork)
plot1|plot2
```

The histogram in figure1 shows the BMI data to follow a normal distribution, although slightly right skewed. Similarly the Q-Q plot in figure2 shows the data points lie close to the diagonal line but show a slight upward curve at both ends. This does not cause too much concern, so we shall continue to fit a linear regression model.

We fit the model:

$$BMI_i = \alpha + \beta_{\mathrm{Age}} \cdot Age_i + \beta_{\mathrm{Male}} \cdot \mathbb{I}_{\mathrm{Male}}(x_i) + \beta_{\mathrm{Education}} \cdot \mathbb{I}_{\mathrm{Education}}(x_i) + \beta_{\mathrm{Veg}} \cdot \mathbb{I}_{\mathrm{Veg}}(x_i) + \beta_{\mathrm{Fruit}} \cdot \mathbb{I}_{\mathrm{Fruit}}(x_i) + \epsilon_i,$$

```{r}
lm_spec <- linear_reg() |> set_engine("lm")
full.model <- lm_spec |> fit(BMI ~ Age + Sex + Education + Veg + Fruit, data = bmi.data)
full.model <- full.model |> extract_fit_engine()
get_regression_table(full.model)
```

From the regression table, we can see that the significance of the variables "Sex: Male", "Veg: Yes" and "Fruit: Yes" all include 0 in their confidence intervals and have a p-value that exceeds 0.05. This causes us to question whether these variables are significant in telling us anything about the BMI distribution. We will remove them from the model:

$$BMI_i = \alpha + \beta_{\mathrm{Age}} \cdot Age_i + \beta_{\mathrm{Education}} \cdot \mathbb{I}_{\mathrm{Education}}(x_i) + \epsilon_i,$$

```{r}
lm_spec <- linear_reg() |> set_engine("lm")
parallel.model.reduced <- lm_spec |> fit(BMI ~ Age + Education, data = bmi.data)
parallel.model.reduced <- parallel.model.reduced |> extract_fit_engine()
get_regression_table(parallel.model.reduced)
```

Now we consider whether interactions may improve the model. As our reduced model only considers Age and Education as statistically significant, we shall fit a model that considers the interaction between them, :

```{r}
lm_spec <- linear_reg()
interaction.model <- lm_spec |> fit(BMI ~ Age * Education, data = bmi.data)
interaction.model <- interaction.model |> extract_fit_engine()
get_regression_table(interaction.model)
```

Now to compare the models:

Now that we have 3 models, we compare them using objective criteria. We shall compare the full model, interaction model and reduced model for BIC, AIC and R squared adjusted:

```{r}
lm_spec <- linear_reg()
interaction.model <- lm_spec |> fit(BMI ~ Age * Education, data = bmi.data)
interaction.model <- interaction.model |> extract_fit_engine()
get_regression_table(interaction.model)
```

Now to compare the models:

```{r}
regression.points <- get_regression_points(interaction.model)
head(regression.points)
```

Now that we have 3 models, we compare them using objective criteria. We shall compare the full model, interaction model and reduced model for BIC, AIC and R squared adjusted

```{r}
mlr.model.full <- linear_reg() |> 
  fit(BMI ~ Age + Sex + Education + Veg + Fruit, data = bmi.data) |> 
  extract_fit_engine()

mlr.model.reduced <- linear_reg() |> 
  fit(BMI ~ Age + Education, data = bmi.data) |> 
  extract_fit_engine()


mlr.model.interaction <- linear_reg() |> 
  fit(BMI ~ Age * Education, data = bmi.data) |> 
  extract_fit_engine()


model_comparison <- bind_rows(
  tibble(model = "Full Model", 
         AIC = AIC(mlr.model.full),
         BIC = BIC(mlr.model.full),
         Adjusted_R_squared = summary(mlr.model.full)$adj.r.squared),
  tibble(model = "Interaction Model", 
         AIC = AIC(mlr.model.interaction),
         BIC = BIC(mlr.model.interaction),
         Adjusted_R_squared = summary(mlr.model.interaction)$adj.r.squared),
  tibble(model = "Reduced Model", 
         AIC = AIC(mlr.model.reduced),
         BIC = BIC(mlr.model.reduced),
         Adjusted_R_squared = summary(mlr.model.reduced)$adj.r.squared)
)
model_comparison
```

# Conclusions {#sec-con}



